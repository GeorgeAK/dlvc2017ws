{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DLVC WS 2017\n",
    "\n",
    "Tutorial 7: Stacked Denoising and Sparse Autoencoders\n",
    "=="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Packages\n",
    "=="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.autograd import Function\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data:\n",
    "==============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "BatchSize = 1000\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./MNIST', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BatchSize,\n",
    "                                          shuffle=True, num_workers=4) # Creating dataloader\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./MNIST', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BatchSize,\n",
    "                                         shuffle=False, num_workers=4) # Creating dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available!\n"
     ]
    }
   ],
   "source": [
    "# Check availability of GPU\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    print('GPU is available!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the Sparse Autoencoder:\n",
    "==============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class L1Penalty(Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, l1weight):\n",
    "        ctx.save_for_backward(input)\n",
    "        ctx.l1weight = l1weight\n",
    "        return input\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input, = ctx.saved_variables\n",
    "        grad_input = input.clone().sign().mul(self.l1weight)\n",
    "        grad_input += grad_output\n",
    "        return grad_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "autoencoder (\n",
      "  (encoder): Sequential (\n",
      "    (0): Linear (784 -> 400)\n",
      "    (1): Tanh ()\n",
      "  )\n",
      "  (decoder): Sequential (\n",
      "    (0): Linear (400 -> 784)\n",
      "    (1): Tanh ()\n",
      "    (2): ReLU ()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28*28, 400),\n",
    "            nn.Tanh())\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(400, 28*28),\n",
    "            nn.Tanh(),\n",
    "            nn.ReLU())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = L1Penalty.apply(x, 0.1)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = autoencoder()\n",
    "print(net)\n",
    "\n",
    "if use_gpu:\n",
    "    net = net.double().cuda()\n",
    "else:\n",
    "    net = net.double()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Autoencoder:\n",
    "==========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At Iteration : 1 / 20  ;  Mean-Squared Error : 0.041360\n",
      "At Iteration : 2 / 20  ;  Mean-Squared Error : 0.015700\n",
      "At Iteration : 3 / 20  ;  Mean-Squared Error : 0.009962\n",
      "At Iteration : 4 / 20  ;  Mean-Squared Error : 0.007664\n",
      "At Iteration : 5 / 20  ;  Mean-Squared Error : 0.006520\n",
      "At Iteration : 6 / 20  ;  Mean-Squared Error : 0.005834\n",
      "At Iteration : 7 / 20  ;  Mean-Squared Error : 0.005385\n",
      "At Iteration : 8 / 20  ;  Mean-Squared Error : 0.005087\n",
      "At Iteration : 9 / 20  ;  Mean-Squared Error : 0.004869\n",
      "At Iteration : 10 / 20  ;  Mean-Squared Error : 0.004706\n",
      "At Iteration : 11 / 20  ;  Mean-Squared Error : 0.004579\n",
      "At Iteration : 12 / 20  ;  Mean-Squared Error : 0.004464\n",
      "At Iteration : 13 / 20  ;  Mean-Squared Error : 0.004387\n",
      "At Iteration : 14 / 20  ;  Mean-Squared Error : 0.004317\n",
      "At Iteration : 15 / 20  ;  Mean-Squared Error : 0.004255\n",
      "At Iteration : 16 / 20  ;  Mean-Squared Error : 0.004215\n",
      "At Iteration : 17 / 20  ;  Mean-Squared Error : 0.004155\n",
      "At Iteration : 18 / 20  ;  Mean-Squared Error : 0.004117\n",
      "At Iteration : 19 / 20  ;  Mean-Squared Error : 0.004089\n",
      "At Iteration : 20 / 20  ;  Mean-Squared Error : 0.004046\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "iterations = 20\n",
    "learning_rate = 1e-3\n",
    "noise_mean = 0.1\n",
    "noise_std = 0.2\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr = learning_rate) # Adam optimizer for optimization\n",
    "for epoch in range(iterations):  # loop over the dataset multiple times\n",
    "\n",
    "    runningLoss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # wrap them in Variable\n",
    "        if use_gpu:\n",
    "            ideal_outputs = Variable(inputs.view(-1, 28*28).double()).cuda()\n",
    "            noise = Variable(ideal_outputs.data.new(ideal_outputs.size()).normal_(noise_mean, noise_std).double()).cuda()\n",
    "            inputs = Variable(torch.clamp((ideal_outputs + noise).data,0,1).double()).cuda()\n",
    "        else:\n",
    "            ideal_outputs = Variable(inputs.view(-1, 28*28).double())\n",
    "            noise = Variable(ideal_outputs.data.new(ideal_outputs.size()).normal_(noise_mean, noise_std).double())\n",
    "            inputs = Variable(torch.clamp((ideal_outputs + noise).data,0,1).double())\n",
    "\n",
    "        optimizer.zero_grad()  # zeroes the gradient buffers of all parameters\n",
    "        outputs = net(inputs) # forward \n",
    "        loss = criterion(outputs, ideal_outputs) # calculate loss\n",
    "        loss.backward() #  backpropagate the loss\n",
    "        optimizer.step()\n",
    "        runningLoss += loss.data[0]\n",
    "    print('At Iteration : %d / %d  ;  Mean-Squared Error : %f'%(epoch + 1,iterations,\n",
    "                                                                        runningLoss/(60000/BatchSize)))\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Stacked Denoising and Sparse Autoencoder:\n",
    "================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "autoencoder (\n",
      "  (encoder): Sequential (\n",
      "    (0): Linear (784 -> 400)\n",
      "    (1): Tanh ()\n",
      "    (New_Encoder_Layer): Sequential (\n",
      "      (0): Linear (400 -> 256)\n",
      "      (1): Tanh ()\n",
      "    )\n",
      "    (New_Decoder_Layer): Sequential (\n",
      "      (0): Linear (256 -> 400)\n",
      "      (1): Tanh ()\n",
      "    )\n",
      "  )\n",
      "  (decoder): Sequential (\n",
      "    (0): Linear (400 -> 784)\n",
      "    (1): Tanh ()\n",
      "    (2): ReLU ()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Adding New Layer (Stacking)\n",
    "net.encoder.add_module('New_Encoder_Layer', nn.Sequential(nn.Linear(400, 256),nn.Tanh()))\n",
    "net.encoder.add_module('New_Decoder_Layer', nn.Sequential(nn.Linear(256, 400),nn.Tanh()))\n",
    "print(net)\n",
    "if use_gpu:\n",
    "    net = net.double().cuda()\n",
    "else:\n",
    "    net = net.double()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Autoencoder:\n",
    "=========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At Iteration : 1 / 20  ;  Mean-Squared Error : 0.036467\n",
      "At Iteration : 2 / 20  ;  Mean-Squared Error : 0.015230\n",
      "At Iteration : 3 / 20  ;  Mean-Squared Error : 0.011140\n",
      "At Iteration : 4 / 20  ;  Mean-Squared Error : 0.009267\n",
      "At Iteration : 5 / 20  ;  Mean-Squared Error : 0.008223\n",
      "At Iteration : 6 / 20  ;  Mean-Squared Error : 0.007520\n",
      "At Iteration : 7 / 20  ;  Mean-Squared Error : 0.007031\n",
      "At Iteration : 8 / 20  ;  Mean-Squared Error : 0.006653\n",
      "At Iteration : 9 / 20  ;  Mean-Squared Error : 0.006358\n",
      "At Iteration : 10 / 20  ;  Mean-Squared Error : 0.006123\n",
      "At Iteration : 11 / 20  ;  Mean-Squared Error : 0.005919\n",
      "At Iteration : 12 / 20  ;  Mean-Squared Error : 0.005748\n",
      "At Iteration : 13 / 20  ;  Mean-Squared Error : 0.005614\n",
      "At Iteration : 14 / 20  ;  Mean-Squared Error : 0.005490\n",
      "At Iteration : 15 / 20  ;  Mean-Squared Error : 0.005393\n",
      "At Iteration : 16 / 20  ;  Mean-Squared Error : 0.005297\n",
      "At Iteration : 17 / 20  ;  Mean-Squared Error : 0.005202\n",
      "At Iteration : 18 / 20  ;  Mean-Squared Error : 0.005120\n",
      "At Iteration : 19 / 20  ;  Mean-Squared Error : 0.005074\n",
      "At Iteration : 20 / 20  ;  Mean-Squared Error : 0.005011\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(iterations):  # loop over the dataset multiple times\n",
    "\n",
    "    runningLoss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # wrap them in Variable\n",
    "        if use_gpu:\n",
    "            ideal_outputs = Variable(inputs.view(-1, 28*28).double()).cuda()\n",
    "            noise = Variable(ideal_outputs.data.new(ideal_outputs.size()).normal_(noise_mean, noise_std).double()).cuda()\n",
    "            inputs = Variable(torch.clamp((ideal_outputs + noise).data,0,1).double()).cuda()\n",
    "        else:\n",
    "            ideal_outputs = Variable(inputs.view(-1, 28*28).double())\n",
    "            noise = Variable(ideal_outputs.data.new(ideal_outputs.size()).normal_(noise_mean, noise_std).double())\n",
    "            inputs = Variable(torch.clamp((ideal_outputs + noise).data,0,1).double())\n",
    "\n",
    "        optimizer.zero_grad()  # zeroes the gradient buffers of all parameters\n",
    "        outputs = net(inputs) # forward \n",
    "        loss = criterion(outputs, ideal_outputs) # calculate loss\n",
    "        loss.backward() #  backpropagate the loss\n",
    "        optimizer.step()\n",
    "        runningLoss += loss.data[0]\n",
    "    print('At Iteration : %d / %d  ;  Mean-Squared Error : %f'%(epoch + 1,iterations,\n",
    "                                                                        runningLoss/(60000/BatchSize)))\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Autoencoder Performance:\n",
    "================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAADPCAYAAADlGSpRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc32dd10550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# functions to show an image\n",
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "if use_gpu:\n",
    "    ideal_outputs = Variable(images[0].view(-1,28*28).double()).cuda()\n",
    "    noise = Variable(ideal_outputs.data.new(ideal_outputs.size()).normal_(noise_mean, noise_std).double()).cuda()\n",
    "    inputs = ideal_outputs + noise\n",
    "    outImg = net(inputs).data\n",
    "    outImg = outImg.view(-1,28,28).cpu()\n",
    "else:\n",
    "    ideal_outputs = Variable(images[0].view(-1,28*28).double())\n",
    "    noise = Variable(ideal_outputs.data.new(ideal_outputs.size()).normal_(noise_mean, noise_std).double())\n",
    "    inputs = ideal_outputs + noise\n",
    "    outImg = net(inputs).data\n",
    "    outImg = outImg.view(-1,28,28)\n",
    "\n",
    "dispImg = torch.Tensor(2,1,28,28)\n",
    "dispImg[0] = torch.clamp(inputs.data.view(-1,28,28).cpu(),0,1)\n",
    "dispImg[1] = outImg\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(dispImg))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
